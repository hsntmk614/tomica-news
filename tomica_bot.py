import requests
from bs4 import BeautifulSoup
import json
import os
import xml.etree.ElementTree as ET

# --- è¨­å®šéƒ¨åˆ† ---
LINE_CHANNEL_ACCESS_TOKEN = os.environ.get("LINE_CHANNEL_ACCESS_TOKEN", "")
LINE_USER_ID = os.environ.get("LINE_USER_ID", "")

HISTORY_FILE = "tomica_history.json"

def send_line_message(message_text):
    if not LINE_CHANNEL_ACCESS_TOKEN or not LINE_USER_ID:
        print("LINEã®éµãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return
        
    endpoint = "https://api.line.me/v2/bot/message/push"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {LINE_CHANNEL_ACCESS_TOKEN}"
    }
    payload = {
        "to": LINE_USER_ID,
        "messages": [{"type": "text", "text": message_text}]
    }
    
    try:
        response = requests.post(endpoint, headers=headers, json=payload, timeout=10)
        if response.status_code != 200:
            print(f"LINEé€šçŸ¥ã‚¨ãƒ©ãƒ¼: {response.text}")
    except Exception as e:
        print(f"LINEé€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")

def load_history():
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except json.JSONDecodeError:
            return []
    return []

def save_history(history):
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=4)

def check_new_tomica():
    print("ãƒˆãƒŸã‚«ã®æœ€æ–°æƒ…å ±ã‚’ãƒã‚§ãƒƒã‚¯ä¸­...")
    history = load_history()
    new_items_found = False

    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    } 

    # --- â‘  ã‚¿ã‚«ãƒ©ãƒˆãƒŸãƒ¼å…¬å¼ ï¼† ãƒˆãƒŸã‚«ã”ãƒ¼ã”ãƒ¼ ã®ãƒã‚§ãƒƒã‚¯ ---
    HTML_TARGETS = [
        "https://takaratomymall.jp/shop/c/cTomica/",
        "https://tomicagogo.com/"  # â†ã”æŒ‡å®šã®æœ€å¼·ã‚µã‚¤ãƒˆã‚’è¿½åŠ ã—ã¾ã—ãŸï¼
    ]

    for url in HTML_TARGETS:
        try:
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            
            for link in soup.find_all('a'):
                title = link.text.strip()
                href = link.get('href')
                
                # ã€ŒãƒˆãƒŸã‚«ã€ã¨ã„ã†æ–‡å­—ãŒå«ã¾ã‚Œã‚‹ãƒªãƒ³ã‚¯ã‚’æ‹¾ã†
                if title and href and "ãƒˆãƒŸã‚«" in title:
                    if href.startswith('/'):
                        domain = "/".join(url.split("/")[:3])
                        full_url = domain + href
                    else:
                        full_url = href

                    if full_url not in history and full_url.startswith("http"):
                        message = f"ğŸš— æ–°ç€ãƒˆãƒŸã‚«æƒ…å ±ï¼\n{title}\n{full_url}"
                        print(message)
                        send_line_message(message)
                        history.append(full_url)
                        new_items_found = True
        except requests.exceptions.Timeout:
            print(f"é€šä¿¡ã‚¨ãƒ©ãƒ¼ ({url}): å¿œç­”ãŒé…ã„ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")
        except Exception as e:
            print(f"ã‚µã‚¤ãƒˆãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼ ({url}): {e}")

    # --- â‘¡ Googleãƒ‹ãƒ¥ãƒ¼ã‚¹ ã®ãƒã‚§ãƒƒã‚¯ ---
    # ã€ŒãƒˆãƒŸã‚« ç‰¹æ³¨ã€ã€Œã‚ªãƒªã‚¸ãƒŠãƒ«ãƒˆãƒŸã‚«ã€ã€ŒãƒˆãƒŸã‚« äºˆç´„ã€ã§æ¤œç´¢ã—ãŸæœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ‹¾ã„ã¾ã™
    GOOGLE_NEWS_URL = "https://news.google.com/rss/search?q=ãƒˆãƒŸã‚«+ç‰¹æ³¨+OR+ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒˆãƒŸã‚«+OR+ãƒˆãƒŸã‚«+äºˆç´„&hl=ja&gl=JP&ceid=JP:ja"
    try:
        response = requests.get(GOOGLE_NEWS_URL, headers=headers, timeout=10)
        response.raise_for_status()
        
        # ãƒ‹ãƒ¥ãƒ¼ã‚¹ç”¨ã®ç‰¹åˆ¥ãªãƒ‡ãƒ¼ã‚¿(XML)ã‚’è§£èª­ã™ã‚‹å‡¦ç†
        root = ET.fromstring(response.text)
        for item in root.findall('.//item'):
            title = item.find('title').text
            link = item.find('link').text
            
            if link not in history:
                message = f"ğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹ç™ºè¦‹ï¼\n{title}\n{link}"
                print(message)
                send_line_message(message)
                history.append(link)
                new_items_found = True
    except Exception as e:
        print(f"Googleãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")

    # --- ä¿å­˜å‡¦ç† ---
    if new_items_found:
        save_history(history[-400:]) # å±¥æ­´ãŒå¢—ãˆã™ããªã„ã‚ˆã†æœ€æ–°400ä»¶ã ã‘è¦šãˆã‚‹
        print("ãƒã‚§ãƒƒã‚¯å®Œäº†ã€‚æ–°ç€æƒ…å ±ã‚’é€šçŸ¥ã—ã¾ã—ãŸã€‚")
    else:
        print("ãƒã‚§ãƒƒã‚¯å®Œäº†ã€‚æ–°ç€æƒ…å ±ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

if __name__ == "__main__":
    check_new_tomica()
