import requests
from bs4 import BeautifulSoup
import json
import os

# --- è¨­å®šéƒ¨åˆ† ---
# LINE Notifyã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã—ã¾ã™
LINE_NOTIFY_TOKEN = os.environ.get("LINE_TOKEN", "")

# ç›£è¦–ã—ãŸã„ã‚µã‚¤ãƒˆã®URLãƒªã‚¹ãƒˆï¼ˆä¾‹ï¼šã‚¿ã‚«ãƒ©ãƒˆãƒŸãƒ¼ãƒ¢ãƒ¼ãƒ«ï¼‰
TARGET_URLS = [
    "https://takaratomymall.jp/shop/c/cTomica/",
]

# éå»ã«é€šçŸ¥ã—ãŸæƒ…å ±ã‚’è¨˜éŒ²ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«
HISTORY_FILE = "tomica_history.json"

def send_line_notify(message):
    """LINEã«é€šçŸ¥ã‚’é€ã‚‹é–¢æ•°"""
    if not LINE_NOTIFY_TOKEN:
        print("LINEãƒˆãƒ¼ã‚¯ãƒ³ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return
        
    line_notify_api = 'https://notify-api.line.me/api/notify'
    headers = {'Authorization': f'Bearer {LINE_NOTIFY_TOKEN}'}
    data = {'message': f'\n{message}'}
    requests.post(line_notify_api, headers=headers, data=data)

def load_history():
    """éå»ã®é€šçŸ¥å±¥æ­´ã‚’èª­ã¿è¾¼ã‚€"""
    if os.path.exists(HISTORY_FILE):
        with open(HISTORY_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return []

def save_history(history):
    """é€šçŸ¥å±¥æ­´ã‚’ä¿å­˜ã™ã‚‹"""
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=4)

def check_new_tomica():
    """ã‚µã‚¤ãƒˆã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦æ–°ç€ãŒã‚ã‚Œã°é€šçŸ¥ã™ã‚‹ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ãƒˆãƒŸã‚«ã®æœ€æ–°æƒ…å ±ã‚’ãƒã‚§ãƒƒã‚¯ä¸­...")
    history = load_history()
    new_items_found = False

    for url in TARGET_URLS:
        try:
            # ã‚µã‚¤ãƒˆã¸ã®è² è·ã‚’ä¸‹ã’ã‚‹ãŸã‚ã®è¨­å®š
            headers = {'User-Agent': 'Mozilla/5.0'} 
            response = requests.get(url, headers=headers)
            response.raise_for_status()
            
            # HTMLã‚’è§£æ
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ãƒªãƒ³ã‚¯(aã‚¿ã‚°)ã‹ã‚‰ã€ŒãƒˆãƒŸã‚«ã€ã¨ã„ã†æ–‡å­—ã‚’å«ã‚€ã‚‚ã®ã‚’æ¢ã™
            links = soup.find_all('a')
            
            for link in links:
                title = link.text.strip()
                href = link.get('href')
                
                # ã‚¿ã‚¤ãƒˆãƒ«ã«ã€ŒãƒˆãƒŸã‚«ã€ãŒå«ã¾ã‚Œã¦ã„ã¦ã€ã¾ã é€šçŸ¥ã—ã¦ã„ãªã„å ´åˆ
                if "ãƒˆãƒŸã‚«" in title and href:
                    if href.startswith('/'):
                        domain = "/".join(url.split("/")[:3])
                        full_url = domain + href
                    else:
                        full_url = href

                    item_id = full_url 
                    
                    if item_id not in history:
                        # æ–°ã—ã„ãƒˆãƒŸã‚«æƒ…å ±ç™ºè¦‹ï¼
                        message = f"ğŸš— æ–°ç€ãƒˆãƒŸã‚«æƒ…å ±ï¼\n{title}\n{full_url}"
                        print(message)
                        send_line_notify(message)
                        
                        history.append(item_id)
                        new_items_found = True
                        
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ ({url}): {e}")

    # å±¥æ­´ã‚’æ›´æ–°ï¼ˆæœ€æ–°ã®200ä»¶ã ã‘ä¿æŒï¼‰
    if new_items_found:
        save_history(history[-200:])
        print("ãƒã‚§ãƒƒã‚¯å®Œäº†ã€‚æ–°ç€æƒ…å ±ã‚’é€šçŸ¥ã—ã¾ã—ãŸã€‚")
    else:
        print("ãƒã‚§ãƒƒã‚¯å®Œäº†ã€‚æ–°ç€æƒ…å ±ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

if __name__ == "__main__":
    check_new_tomica()
